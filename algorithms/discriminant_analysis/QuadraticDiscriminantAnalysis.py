from core.BaseEstimator import BaseEstimator
from utils.ClassificationMetrics import accuracy_score
import numpy as np

class QuadraticDiscriminantAnalysis(BaseEstimator):
  '''
  Quadratic Discriminant Analysis (QDA)
  
  sklearn: A classifer with quadratic decision boundary, generated by fitting class conditional
  densities to the data and using Bayes' rule.
  '''

  def __init__(self, priors=None):
    super().__init__('QDA', 'Discriminant Analysis', accuracy_score)
    self.priors = priors 

  def fit(self, X, y):
    # Cast to numpy arrays
    if not isinstance(X, np.ndarray):
      X = np.asarray(X)
    if not isinstance(y, np.ndarray):
      y = np.asarray(y) 

    # Cast priors to numpy array
    if self.priors is not None:
      self.priors = np.asarray(self.priors)
    else:
      self.priors = np.bincount(y) / float(len(y)) # Estimating the probability of each class from the data

    # Get unique classes
    self.classes_ = np.unique(y)
    n_features, n_classes = X.shape[1], len(self.classes_)
    self.means_ = np.zeros((n_classes, n_features))
    self.covariance_ = np.zeros((n_classes, n_features, n_features))

    # Calculate means and covariance matrices
    for i, y_i in enumerate(self.classes_):
      X_i = X[y == y_i]
      n_i = len(X_i)
      self.means_[i] = X_i.mean(axis=0)
      self.covariance_[i] = np.cov(X_i, bias=True, rowvar=False)

    # Calculate the inverse of the covariance matrices, a pre computation instead of calculating it every time in predictions
    self.inv_cov_ = np.zeros((n_classes, n_features, n_features))
    for i in range(n_classes):
      self.inv_cov_[i] = np.linalg.inv(self.covariance_[i])

    print('Quadratic Discriminant Analysis model has been trained.')

  def predict(self, X):
    '''
    Shapes:
      - X: (n_samples, n_features)
      - means_: (n_classes, n_features)
      - covariance_: (n_classes, n_features, n_features)
      - priors: (n_classes)
    '''
    if not isinstance(X, np.ndarray):
      X = np.asarray(X)

    n_classes = len(self.classes_)
    decision = np.zeros((X.shape[0], n_classes))
    for i, y_i in enumerate(self.classes_):
      diff = X - self.means_[i]
      cov = self.covariance_[i]
      inv_cov = self.inv_cov_[i]
      # Calculate the log of the determinant of the covariance matrix
      log_det = np.log(np.linalg.det(cov))

      decision[:, i] = -0.5 * np.sum(diff @ inv_cov * diff, axis=1) - 0.5 * log_det + np.log(self.priors[i])

    return self.classes_[np.argmax(decision, axis=1)]

  def evaluate(self, X, y, metric=accuracy_score):
    preds = self.predict(X)
    return metric(y, preds)
  
  def score(self, X, y):
    return self.evaluate(X, y, self._base_metric)
  
  def clone(self):
    return QuadraticDiscriminantAnalysis(self.priors)