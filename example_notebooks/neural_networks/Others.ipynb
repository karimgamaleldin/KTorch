{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other examples\n",
    "A notebook to test simple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\KTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from nn import Flatten, Linear, Dropout\n",
    "from core import KTorch\n",
    "from autograd import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 49152), 49152)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(6, 128, 128, 3).astype(np.float32)\n",
    "x_tensor = Tensor(x)\n",
    "flatten = Flatten()\n",
    "flatten(x_tensor).shape, 128*128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare output\n",
    "flattened = flatten(x_tensor)\n",
    "np_flattened = x.reshape(6, -1)\n",
    "np.equal(flattened.data, np_flattened).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(6, 128, 128, 3).astype(np.float32)\n",
    "x_tensor = Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "flatten = Flatten()\n",
    "linear = Linear(128*128*3, 10)\n",
    "\n",
    "# Forward pass\n",
    "flattened = flatten(x_tensor)\n",
    "output = linear(flattened)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual forward pass\n",
    "\n",
    "# Parameters\n",
    "w = linear.weight.data\n",
    "b = linear.bias.data\n",
    "\n",
    "np_flattened = x.reshape(6, -1)\n",
    "manual_output = np_flattened @ w + b\n",
    "np.equal(output.data, manual_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual backward pass\n",
    "grad_output = np.ones_like(output.data)\n",
    "grad_flattened = grad_output @ w.T\n",
    "grad_flattened = grad_flattened.reshape(6, 128, 128, 3)\n",
    "grad_x = grad_flattened\n",
    "w_grad = np_flattened.T @ grad_output\n",
    "b_grad = grad_output.sum(axis=0)\n",
    "\n",
    "np.equal(x_tensor.grad.data, grad_x).all(), np.equal(linear.weight.grad.data, w_grad).all(), np.equal(linear.bias.grad.data, b_grad).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(32, 128).astype(np.float32)\n",
    "x_tensor = Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropout\n",
    "dropout = Dropout(0.5)\n",
    "linear = Linear(128, 10)\n",
    "\n",
    "output, mask = dropout(x_tensor)\n",
    "output = linear(output)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual forward propagation\n",
    "mask_np = mask.data\n",
    "w = linear.weight.data\n",
    "b = linear.bias.data\n",
    "\n",
    "\n",
    "masked = x * mask_np * (1.0 / 0.5)\n",
    "output_np = masked @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 10), True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_np.shape, np.equal(output.data, output_np).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual backward pass\n",
    "grad_output = np.ones_like(output.data)\n",
    "grad_masked = grad_output @ w.T\n",
    "grad_x = grad_masked * mask_np * (1.0 / 0.5)\n",
    "w_grad = masked.T @ grad_output\n",
    "b_grad = grad_output.sum(axis=0)\n",
    "\n",
    "np.equal(x_tensor.grad.data, grad_x).all(), np.equal(linear.weight.grad, w_grad).all(), np.equal(linear.bias.grad, b_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
