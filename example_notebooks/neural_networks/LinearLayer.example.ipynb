{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Layer notebook\n",
    "A notebook to test the implemention of the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\KTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Linear, ReLU, Sigmoid, Tanh, Softmax \n",
    "import numpy as np\n",
    "from autograd import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: 1 Layer NN Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(32, 16).astype(np.float32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32), autograd.engine.Tensor)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KTorch \n",
    "x_tensor = Tensor(x)\n",
    "linear = Linear(16, 32)\n",
    "my_output = linear.forward(x_tensor)\n",
    "my_output.shape, type(my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 32), (32,), (32, 16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test matrix multiplication\n",
    "weights = linear.weight.numpy()\n",
    "bias = linear.bias.numpy()\n",
    "weights.shape, bias.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_output = np.dot(x, weights) + bias\n",
    "manual_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare outputs\n",
    "np.equal(my_output.numpy(), manual_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop ktorch\n",
    "my_output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 32), (32,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_grad = linear.weight.grad\n",
    "b_grad = linear.bias.grad\n",
    "w_grad.shape, b_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 32), (32,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually\n",
    "manual_w_grad = np.dot(x.T, np.ones_like(manual_output))\n",
    "manual_b_grad = np.ones_like(manual_output).sum(axis=0)\n",
    "manual_w_grad.shape, manual_b_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare gradients\n",
    "np.equal(w_grad, manual_w_grad).all(), np.equal(b_grad, manual_b_grad).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: 4 Layers NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "# inputs\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(32, 16).astype(np.float32)\n",
    "x_tensor = Tensor(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 16), autograd.engine.Tensor)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our layers\n",
    "linear1 = Linear(16, 32)\n",
    "linear2 = Linear(32, 64)\n",
    "linear3 = Linear(64, 32)\n",
    "linear4 = Linear(32, 16)\n",
    "\n",
    "my_output = linear1.forward(x_tensor)\n",
    "my_output = linear2.forward(my_output)\n",
    "my_output = linear3.forward(my_output)\n",
    "my_output = linear4.forward(my_output)\n",
    "\n",
    "my_output.shape, type(my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual forward pass\n",
    "weights1 = linear1.weight.numpy()\n",
    "bias1 = linear1.bias.numpy()\n",
    "weights2 = linear2.weight.numpy()\n",
    "bias2 = linear2.bias.numpy()\n",
    "weights3 = linear3.weight.numpy()\n",
    "bias3 = linear3.bias.numpy()\n",
    "weights4 = linear4.weight.numpy()\n",
    "bias4 = linear4.bias.numpy()\n",
    "\n",
    "h1 = np.dot(x, weights1) + bias1\n",
    "h2 = np.dot(h1, weights2) + bias2\n",
    "h3 = np.dot(h2, weights3) + bias3\n",
    "manual_output = np.dot(h3, weights4) + bias4\n",
    "manual_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare outputs\n",
    "np.equal(my_output.numpy(), manual_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop ktorch\n",
    "my_output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True, True, True, True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradients\n",
    "w1_grad = linear1.weight.grad\n",
    "b1_grad = linear1.bias.grad\n",
    "w2_grad = linear2.weight.grad\n",
    "b2_grad = linear2.bias.grad\n",
    "w3_grad = linear3.weight.grad\n",
    "b3_grad = linear3.bias.grad\n",
    "w4_grad = linear4.weight.grad\n",
    "b4_grad = linear4.bias.grad\n",
    "\n",
    "w1_grad.shape == weights1.shape, b1_grad.shape == bias1.shape, w2_grad.shape == weights2.shape, b2_grad.shape == bias2.shape, w3_grad.shape == weights3.shape, b3_grad.shape == bias3.shape, w4_grad.shape == weights4.shape, b4_grad.shape == bias4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 4)\n",
    "manual_output_grad = np.ones_like(manual_output)\n",
    "manual_w4_grad = np.dot(h3.T, manual_output_grad)\n",
    "manual_b4_grad = manual_output_grad.sum(axis=0)\n",
    "np.equal(w4_grad, manual_w4_grad).all(), np.equal(b4_grad, manual_b4_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 3)\n",
    "h3_grad = np.dot(manual_output_grad, weights4.T)\n",
    "manual_w3_grad = np.dot(h2.T, h3_grad)\n",
    "manual_b3_grad = h3_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w3_grad, manual_w3_grad).all(), np.equal(b3_grad, manual_b3_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 2)\n",
    "h2_grad = np.dot(h3_grad, weights3.T)\n",
    "manual_w2_grad = np.dot(h1.T, h2_grad)\n",
    "manual_b2_grad = h2_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w2_grad, manual_w2_grad).all(), np.equal(b2_grad, manual_b2_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 1)\n",
    "h1_grad = np.dot(h2_grad, weights2.T)\n",
    "manual_w1_grad = np.dot(x.T, h1_grad)\n",
    "manual_b1_grad = h1_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w1_grad, manual_w1_grad).all(), np.equal(b1_grad, manual_b1_grad).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Test Activation functions with 5 layered nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(6, 16).astype(np.float32)\n",
    "x_tensor = Tensor(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 16), autograd.engine.Tensor)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our layers\n",
    "linear1 = Linear(16, 32)\n",
    "relu = ReLU()\n",
    "linear2 = Linear(32, 64)\n",
    "sigmoid = Sigmoid()\n",
    "linear3 = Linear(64, 32)\n",
    "tanh = Tanh()\n",
    "linear4 = Linear(32, 16)\n",
    "\n",
    "my_output = linear1.forward(x_tensor)\n",
    "my_output = relu.forward(my_output)\n",
    "my_output = linear2.forward(my_output)\n",
    "my_output = sigmoid.forward(my_output)\n",
    "my_output = linear3.forward(my_output)\n",
    "my_output = tanh.forward(my_output)\n",
    "my_output = linear4.forward(my_output)\n",
    "\n",
    "my_output.shape, type(my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 32)\n",
      "(6, 32)\n",
      "(6, 64)\n",
      "(6, 64)\n",
      "(6, 32)\n",
      "(6, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import erf\n",
    "# manual forward pass\n",
    "weights1 = linear1.weight.numpy()\n",
    "bias1 = linear1.bias.numpy()\n",
    "weights2 = linear2.weight.numpy()\n",
    "bias2 = linear2.bias.numpy()\n",
    "weights3 = linear3.weight.numpy()\n",
    "bias3 = linear3.bias.numpy()\n",
    "weights4 = linear4.weight.numpy()\n",
    "bias4 = linear4.bias.numpy()\n",
    "\n",
    "h1 = np.dot(x, weights1) + bias1\n",
    "print(h1.shape)\n",
    "h2 = np.maximum(h1, 0)\n",
    "print(h2.shape)\n",
    "h3 = np.dot(h2, weights2) + bias2\n",
    "print(h3.shape)\n",
    "h4 = 1 / (1 + np.exp(-h3))\n",
    "print(h4.shape)\n",
    "h5 = np.dot(h4, weights3) + bias3\n",
    "print(h5.shape)\n",
    "h6 = np.tanh(h5)\n",
    "print(h6.shape)\n",
    "manual_output = np.dot(h6, weights4) + bias4\n",
    "manual_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare outputs\n",
    "np.equal(my_output.numpy(), manual_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop ktorch\n",
    "my_output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True, True, True, True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradients\n",
    "w1_grad = linear1.weight.grad\n",
    "b1_grad = linear1.bias.grad\n",
    "w2_grad = linear2.weight.grad\n",
    "b2_grad = linear2.bias.grad\n",
    "w3_grad = linear3.weight.grad\n",
    "b3_grad = linear3.bias.grad\n",
    "w4_grad = linear4.weight.grad\n",
    "b4_grad = linear4.bias.grad\n",
    "\n",
    "w1_grad.shape == weights1.shape, b1_grad.shape == bias1.shape, w2_grad.shape == weights2.shape, b2_grad.shape == bias2.shape, w3_grad.shape == weights3.shape, b3_grad.shape == bias3.shape, w4_grad.shape == weights4.shape, b4_grad.shape == bias4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (output layer)\n",
    "manual_output_grad = np.ones_like(manual_output) # dL/dL = 1\n",
    "manual_w4_grad = np.dot(h6.T, manual_output_grad)\n",
    "manual_b4_grad = manual_output_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w4_grad, manual_w4_grad).all(), np.equal(b4_grad, manual_b4_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 8 + 7)\n",
    "h6_grad = np.dot(manual_output_grad, weights4.T)\n",
    "h5_grad = h6_grad * (1 - h6**2)\n",
    "manual_w3_grad = np.dot(h4.T, h5_grad)\n",
    "manual_b3_grad = h5_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w3_grad, manual_w3_grad).all(), np.equal(b3_grad, manual_b3_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 6 + 5)\n",
    "h4_grad = np.dot(h5_grad, weights3.T)\n",
    "h3_grad = h4_grad * h4 * (1 - h4)\n",
    "manual_w2_grad = np.dot(h2.T, h3_grad)\n",
    "manual_b2_grad = h3_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w2_grad, manual_w2_grad).all(), np.equal(b2_grad, manual_b2_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients manually (layer 4 + 3)\n",
    "h2_grad = np.dot(h3_grad, weights2.T)\n",
    "h1_grad = h2_grad * (h2 > 0)\n",
    "manual_w1_grad = np.dot(x.T, h1_grad)\n",
    "manual_b1_grad = h1_grad.sum(axis=0)\n",
    "\n",
    "np.equal(w1_grad, manual_w1_grad).all(), np.equal(b1_grad, manual_b1_grad).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
