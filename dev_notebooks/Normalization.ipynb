{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\KTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from core import KTorch\n",
    "from autograd import Tensor \n",
    "from nn import BatchNorm1D, BatchNorm2D, BatchNorm3D\n",
    "import torch.nn as nn_torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "np.random.seed(42)\n",
    "n1 = np.random.randint(0, 101, (32, 64))\n",
    "\n",
    "# My Tensors\n",
    "t1 = Tensor(n1)\n",
    "\n",
    "# Torch Tensors\n",
    "t1_torch = torch.tensor(n1, requires_grad=True, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64) (1, 64) (1, 64) 1e-05\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32, 64), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BatchNorm1D\n",
    "\n",
    "my_bn1d = BatchNorm1D(64, affine=False, track_running_stats=False, eps=1e-5, momentum=0.1)\n",
    "torch_bn1d = nn_torch.BatchNorm1d(64, affine=False, track_running_stats=False, eps=1e-5, momentum=0.1)\n",
    "\n",
    "# Forward\n",
    "my_bn1d_out = my_bn1d(t1)\n",
    "torch_bn1d_out = torch_bn1d(t1_torch)\n",
    "\n",
    "# Testing equivalence\n",
    "np.testing.assert_allclose(my_bn1d_out.data, torch_bn1d_out.cpu().detach().numpy(), atol=1e-5)\n",
    "\n",
    "my_bn1d_out.shape, torch_bn1d_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing weights and bias (gamma and beta)\n",
    "# np.testing.assert_allclose(my_bn1d.gamma.data, torch_bn1d.weight.cpu().detach().numpy()[None], atol=1e-5)\n",
    "# np.testing.assert_allclose(my_bn1d.beta.data, torch_bn1d.bias.cpu().detach().numpy()[None], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Testing betas grads\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_allclose(\u001b[43mmy_bn1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m, torch_bn1d\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;28;01mNone\u001b[39;00m], atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "# Testing betas grads\n",
    "np.testing.assert_allclose(my_bn1d.beta.grad, torch_bn1d.bias.grad.cpu().detach().numpy()[None], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  4.1723251e-07 -7.7486038e-07  1.9371510e-07\n",
      "   1.2516975e-06  5.0663948e-07 -2.9802322e-07  1.2516975e-06\n",
      "  -1.0728836e-06 -4.7683716e-07  2.9802322e-07 -5.9604645e-08\n",
      "  -1.6391277e-07 -3.5762787e-07 -8.1956387e-07 -2.3841858e-07\n",
      "  -1.1920929e-07  8.6426735e-07  1.1920929e-07 -4.1723251e-07\n",
      "   2.3841858e-07  1.7881393e-07 -5.2154064e-07  1.0132790e-06\n",
      "  -6.5565109e-07  5.9604645e-07 -9.5367432e-07  7.1525574e-07\n",
      "  -2.9802322e-07  1.1920929e-07  7.1525574e-07  4.4703484e-07\n",
      "  -4.4703484e-07  4.7683716e-07  8.9406967e-07 -2.3841858e-07\n",
      "  -1.9371510e-07 -1.2516975e-06 -1.3113022e-06 -1.7881393e-06\n",
      "   2.3841858e-07  1.3839453e-06 -7.1525574e-07 -4.7683716e-07\n",
      "   9.5367432e-07  9.5367432e-07  9.5367432e-07  0.0000000e+00\n",
      "  -5.9604645e-08 -1.3113022e-06 -4.7683716e-07  7.1525574e-07\n",
      "   3.5762787e-07  1.1920929e-07 -2.9802322e-07  3.5762787e-07\n",
      "   8.9406967e-07  4.1723251e-07 -1.1920929e-07  2.9802322e-07\n",
      "   5.9604645e-07 -3.5762787e-07 -8.3446503e-07 -6.8545341e-07]]\n",
      "[-5.0685532e-07  6.5591998e-08 -3.9335404e-07 -8.9544869e-07\n",
      " -3.4162377e-07  2.4428476e-07  3.9837610e-07  3.5022771e-07\n",
      "  2.0325621e-07 -3.3050884e-07  2.3579861e-07 -3.1110199e-07\n",
      " -1.2035623e-07 -1.8603012e-07 -4.8268828e-07 -5.3016174e-07\n",
      " -4.4344611e-07  9.5968562e-07  2.6370375e-07 -3.2199026e-08\n",
      " -7.2951899e-08  6.5999359e-07 -5.2025894e-07  3.8372465e-07\n",
      " -4.3067502e-07  2.7711744e-07 -3.6196815e-07  1.2040352e-06\n",
      "  1.9021704e-07  2.7937492e-07 -3.1679241e-07 -5.1566090e-08\n",
      " -1.8384839e-07  5.3756918e-07 -2.3464005e-07 -7.5162313e-07\n",
      " -2.8841152e-08  1.9848581e-07 -1.2360769e-07 -1.4643465e-06\n",
      " -1.8027151e-07  0.0000000e+00 -4.2448670e-07 -2.2162227e-07\n",
      "  6.0907587e-07 -6.1933844e-07  0.0000000e+00  6.1488500e-08\n",
      " -6.1059474e-08  2.6881585e-07 -4.2659320e-07  0.0000000e+00\n",
      " -8.9227365e-07 -7.1373307e-07 -3.7043199e-07  1.7833447e-07\n",
      "  1.4528619e-07  7.3800271e-07  9.8186831e-08  1.8381175e-07\n",
      "  6.1589964e-07  3.2769773e-08  5.0294528e-07 -5.5613917e-08]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=1e-05\n\n(shapes (1, 64), (64,) mismatch)\n x: array([[ 0.000000e+00,  4.172325e-07, -7.748604e-07,  1.937151e-07,\n         1.251698e-06,  5.066395e-07, -2.980232e-07,  1.251698e-06,\n        -1.072884e-06, -4.768372e-07,  2.980232e-07, -5.960464e-08,...\n y: array([-5.068553e-07,  6.559200e-08, -3.933540e-07, -8.954487e-07,\n       -3.416238e-07,  2.442848e-07,  3.983761e-07,  3.502277e-07,\n        2.032562e-07, -3.305088e-07,  2.357986e-07, -3.111020e-07,...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_bn1d\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch_bn1d\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m----> 4\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_bn1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_bn1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Karim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Karim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\testing\\_private\\utils.py:713\u001b[0m, in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[0;32m    707\u001b[0m         reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(dtypes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mismatch)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    708\u001b[0m     msg \u001b[38;5;241m=\u001b[39m build_err_msg([x, y],\n\u001b[0;32m    709\u001b[0m                         err_msg\n\u001b[0;32m    710\u001b[0m                         \u001b[38;5;241m+\u001b[39m reason,\n\u001b[0;32m    711\u001b[0m                         verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m    712\u001b[0m                         names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[0;32m    715\u001b[0m flagged \u001b[38;5;241m=\u001b[39m bool_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isnumber(x) \u001b[38;5;129;01mand\u001b[39;00m isnumber(y):\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=1e-05\n\n(shapes (1, 64), (64,) mismatch)\n x: array([[ 0.000000e+00,  4.172325e-07, -7.748604e-07,  1.937151e-07,\n         1.251698e-06,  5.066395e-07, -2.980232e-07,  1.251698e-06,\n        -1.072884e-06, -4.768372e-07,  2.980232e-07, -5.960464e-08,...\n y: array([-5.068553e-07,  6.559200e-08, -3.933540e-07, -8.954487e-07,\n       -3.416238e-07,  2.442848e-07,  3.983761e-07,  3.502277e-07,\n        2.032562e-07, -3.305088e-07,  2.357986e-07, -3.111020e-07,..."
     ]
    }
   ],
   "source": [
    "# Testing gammas grads\n",
    "print(my_bn1d.gamma.grad)\n",
    "print(torch_bn1d.weight.grad.cpu().detach().numpy())\n",
    "np.testing.assert_allclose(my_bn1d.gamma.grad, torch_bn1d.weight.grad.cpu().detach().numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "np.random.seed(42)\n",
    "n2 = np.random.randint(0, 101, (32, 64, 128, 128))\n",
    "\n",
    "# My Tensors\n",
    "t2 = Tensor(n2)\n",
    "\n",
    "# Torch Tensors\n",
    "t2_torch = torch.tensor(n2, requires_grad=True, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32, 64, 128, 128), torch.Size([32, 64, 128, 128]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batchnorm 2d\n",
    "\n",
    "my_bn2d = BatchNorm2D(64)\n",
    "torch_bn2d = nn_torch.BatchNorm2d(64)\n",
    "\n",
    "# Forward\n",
    "my_bn2d_out = my_bn2d(t2)\n",
    "torch_bn2d_out = torch_bn2d(t2_torch)\n",
    "\n",
    "# Testing equivalence\n",
    "np.testing.assert_allclose(my_bn2d_out.data, torch_bn2d_out.cpu().detach().numpy(), atol=1e-5)\n",
    "\n",
    "my_bn2d_out.shape, torch_bn2d_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "np.random.seed(42)\n",
    "n3 = np.random.randint(0, 101, (32, 16, 128, 128, 4))\n",
    "\n",
    "# My Tensors\n",
    "t3 = Tensor(n3)\n",
    "\n",
    "# Torch Tensors\n",
    "t3_torch = torch.tensor(n3, requires_grad=True, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((32, 16, 128, 128, 4), torch.Size([32, 16, 128, 128, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batchnorm 2d\n",
    "\n",
    "my_bn3d = BatchNorm3D(16)\n",
    "torch_bn3d = nn_torch.BatchNorm3d(16)\n",
    "\n",
    "# Forward\n",
    "my_bn3d_out = my_bn3d(t3)\n",
    "torch_bn3d_out = torch_bn3d(t3_torch)\n",
    "\n",
    "# Testing equivalence\n",
    "np.testing.assert_allclose(my_bn3d_out.data, torch_bn3d_out.cpu().detach().numpy(), atol=1e-5)\n",
    "\n",
    "my_bn3d_out.shape, torch_bn3d_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
