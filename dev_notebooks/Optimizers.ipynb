{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\KTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karim\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from nn import Sequential, Linear, Sigmoid, MSELoss, ReLU, BCELoss\n",
    "from optim import SGD, Adam, RMSProp, Adagrad, Adadelta\n",
    "import numpy as np\n",
    "from autograd import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regression toy dataset\n",
    "np.random.seed(0)\n",
    "X_reg = np.random.randn(4096, 1)\n",
    "y_reg = 2*X_reg[:,0] + 1\n",
    "X_reg_tensor = Tensor(X_reg)\n",
    "y_reg_tensor = Tensor(y_reg)\n",
    "X_reg_test = np.random.randn(1024, 1)\n",
    "y_reg_test = 2*X_reg_test[:,0] + 1\n",
    "X_reg_test_tensor = Tensor(X_reg_test)\n",
    "y_reg_test_tensor = Tensor(y_reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feed forward neural network for regression and classification\n",
    "regression_feed = Sequential(Linear(1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss()\n",
    "optimizer = SGD(regression_feed.parameters(), lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 4.639421463012695"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.374772548675537, Test_Loss: 4.264626979827881\n",
      "Epoch 2/10, Loss: 4.047688961029053, Test_Loss: 4.118353366851807\n",
      "Epoch 3/10, Loss: 3.9312517642974854, Test_Loss: 4.058586120605469\n",
      "Epoch 4/10, Loss: 3.8897812366485596, Test_Loss: 4.032711982727051\n",
      "Epoch 5/10, Loss: 3.8749923706054688, Test_Loss: 4.020748615264893\n",
      "Epoch 6/10, Loss: 3.8697211742401123, Test_Loss: 4.01484489440918\n",
      "Epoch 7/10, Loss: 3.8678088188171387, Test_Loss: 4.011758804321289\n",
      "Epoch 8/10, Loss: 3.8671815395355225, Test_Loss: 4.010072231292725\n",
      "Epoch 9/10, Loss: 3.866825580596924, Test_Loss: 4.00911808013916\n",
      "Epoch 10/10, Loss: 3.8667945861816406, Test_Loss: 4.008570194244385\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    for i in range(len(weights)):\n",
    "        assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg model\n",
    "np.random.seed(0)\n",
    "regression_feed = Sequential(Linear(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss() \n",
    "optimizer = Adagrad(regression_feed.parameters(), lr=0.1, lr_decay=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 4.378472805023193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.145322322845459, Test_Loss: 4.276494979858398\n",
      "Epoch 2/10, Loss: 4.054826259613037, Test_Loss: 4.230485439300537\n",
      "Epoch 3/10, Loss: 4.016709327697754, Test_Loss: 4.201688289642334\n",
      "Epoch 4/10, Loss: 3.9935734272003174, Test_Loss: 4.181480407714844\n",
      "Epoch 5/10, Loss: 3.9776625633239746, Test_Loss: 4.166351318359375\n",
      "Epoch 6/10, Loss: 3.9659342765808105, Test_Loss: 4.154520034790039\n",
      "Epoch 7/10, Loss: 3.9568750858306885, Test_Loss: 4.144970417022705\n",
      "Epoch 8/10, Loss: 3.949650764465332, Test_Loss: 4.137071132659912\n",
      "Epoch 9/10, Loss: 3.943730354309082, Test_Loss: 4.1304097175598145\n",
      "Epoch 10/10, Loss: 3.938786029815674, Test_Loss: 4.124705791473389\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    # for i in range(len(weights)):\n",
    "    #     assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg model\n",
    "np.random.seed(10)\n",
    "regression_feed = Sequential(Linear(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss() \n",
    "optimizer = RMSProp(regression_feed.parameters(), lr=0.1, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 8.24588680267334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 7.836653232574463, Test_Loss: 6.866888999938965\n",
      "Epoch 2/10, Loss: 6.4604949951171875, Test_Loss: 6.1759490966796875\n",
      "Epoch 3/10, Loss: 5.787445545196533, Test_Loss: 5.718061447143555\n",
      "Epoch 4/10, Loss: 5.3511881828308105, Test_Loss: 5.379574775695801\n",
      "Epoch 5/10, Loss: 5.034807205200195, Test_Loss: 5.116168975830078\n",
      "Epoch 6/10, Loss: 4.7925238609313965, Test_Loss: 4.905875205993652\n",
      "Epoch 7/10, Loss: 4.601797103881836, Test_Loss: 4.735694885253906\n",
      "Epoch 8/10, Loss: 4.4495086669921875, Test_Loss: 4.596948146820068\n",
      "Epoch 9/10, Loss: 4.327034950256348, Test_Loss: 4.483404159545898\n",
      "Epoch 10/10, Loss: 4.228282928466797, Test_Loss: 4.390368461608887\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    # for i in range(len(weights)):\n",
    "    #     assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum and Centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg model\n",
    "np.random.seed(10)\n",
    "regression_feed = Sequential(Linear(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss() \n",
    "optimizer = RMSProp(regression_feed.parameters(), lr=0.01, alpha=0.9, centered=True, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 8.24588680267334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 7.836653232574463, Test_Loss: 8.082048416137695\n",
      "Epoch 2/20, Loss: 7.672534465789795, Test_Loss: 7.8204026222229\n",
      "Epoch 3/20, Loss: 7.410803318023682, Test_Loss: 7.499546051025391\n",
      "Epoch 4/20, Loss: 7.090557098388672, Test_Loss: 7.147330284118652\n",
      "Epoch 5/20, Loss: 6.740151405334473, Test_Loss: 6.784913063049316\n",
      "Epoch 6/20, Loss: 6.381235599517822, Test_Loss: 6.428194522857666\n",
      "Epoch 7/20, Loss: 6.0302019119262695, Test_Loss: 6.088406562805176\n",
      "Epoch 8/20, Loss: 5.698722839355469, Test_Loss: 5.7724714279174805\n",
      "Epoch 9/20, Loss: 5.394085884094238, Test_Loss: 5.483633995056152\n",
      "Epoch 10/20, Loss: 5.119749546051025, Test_Loss: 5.22259521484375\n",
      "Epoch 11/20, Loss: 4.876400947570801, Test_Loss: 4.988846778869629\n",
      "Epoch 12/20, Loss: 4.663214683532715, Test_Loss: 4.7816901206970215\n",
      "Epoch 13/20, Loss: 4.4789934158325195, Test_Loss: 4.600699424743652\n",
      "Epoch 14/20, Loss: 4.322588920593262, Test_Loss: 4.445691108703613\n",
      "Epoch 15/20, Loss: 4.193049907684326, Test_Loss: 4.316455364227295\n",
      "Epoch 16/20, Loss: 4.0893425941467285, Test_Loss: 4.2124552726745605\n",
      "Epoch 17/20, Loss: 4.01015567779541, Test_Loss: 4.1326093673706055\n",
      "Epoch 18/20, Loss: 3.9537193775177, Test_Loss: 4.0752387046813965\n",
      "Epoch 19/20, Loss: 3.9178073406219482, Test_Loss: 4.038112163543701\n",
      "Epoch 20/20, Loss: 3.899780750274658, Test_Loss: 4.018553733825684\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    # for i in range(len(weights)):\n",
    "    #     assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg model\n",
    "np.random.seed(10)\n",
    "regression_feed = Sequential(Linear(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss() \n",
    "optimizer = Adadelta(regression_feed.parameters(), lr=1, rho=0.9, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 8.24588680267334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 7.836653232574463, Test_Loss: 8.230154991149902\n",
      "Epoch 2/20, Loss: 7.8208818435668945, Test_Loss: 8.21407699584961\n",
      "Epoch 3/20, Loss: 7.804764747619629, Test_Loss: 8.197786331176758\n",
      "Epoch 4/20, Loss: 7.788443088531494, Test_Loss: 8.181352615356445\n",
      "Epoch 5/20, Loss: 7.771990776062012, Test_Loss: 8.164816856384277\n",
      "Epoch 6/20, Loss: 7.7554240226745605, Test_Loss: 8.148202896118164\n",
      "Epoch 7/20, Loss: 7.738790988922119, Test_Loss: 8.1315336227417\n",
      "Epoch 8/20, Loss: 7.7220988273620605, Test_Loss: 8.114822387695312\n",
      "Epoch 9/20, Loss: 7.705381393432617, Test_Loss: 8.098081588745117\n",
      "Epoch 10/20, Loss: 7.688632965087891, Test_Loss: 8.081316947937012\n",
      "Epoch 11/20, Loss: 7.671839237213135, Test_Loss: 8.064535140991211\n",
      "Epoch 12/20, Loss: 7.655073165893555, Test_Loss: 8.047746658325195\n",
      "Epoch 13/20, Loss: 7.638267993927002, Test_Loss: 8.030951499938965\n",
      "Epoch 14/20, Loss: 7.621485233306885, Test_Loss: 8.014156341552734\n",
      "Epoch 15/20, Loss: 7.604692459106445, Test_Loss: 7.997365474700928\n",
      "Epoch 16/20, Loss: 7.587906837463379, Test_Loss: 7.980578899383545\n",
      "Epoch 17/20, Loss: 7.571137428283691, Test_Loss: 7.963801860809326\n",
      "Epoch 18/20, Loss: 7.554369926452637, Test_Loss: 7.9470367431640625\n",
      "Epoch 19/20, Loss: 7.537621021270752, Test_Loss: 7.930285453796387\n",
      "Epoch 20/20, Loss: 7.5208940505981445, Test_Loss: 7.913548946380615\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    # for i in range(len(weights)):\n",
    "    #     assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg model\n",
    "np.random.seed(10)\n",
    "regression_feed = Sequential(Linear(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss() \n",
    "optimizer = Adam(regression_feed.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 8.24588680267334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 7.836653232574463, Test_Loss: 7.7674407958984375\n",
      "Epoch 2/20, Loss: 7.357775688171387, Test_Loss: 7.3293328285217285\n",
      "Epoch 3/20, Loss: 6.920571804046631, Test_Loss: 6.9317708015441895\n",
      "Epoch 4/20, Loss: 6.525322914123535, Test_Loss: 6.574288845062256\n",
      "Epoch 5/20, Loss: 6.171714782714844, Test_Loss: 6.255476474761963\n",
      "Epoch 6/20, Loss: 5.85844612121582, Test_Loss: 5.972719669342041\n",
      "Epoch 7/20, Loss: 5.583143711090088, Test_Loss: 5.722104549407959\n",
      "Epoch 8/20, Loss: 5.34201717376709, Test_Loss: 5.49868631362915\n",
      "Epoch 9/20, Loss: 5.130260467529297, Test_Loss: 5.297235012054443\n",
      "Epoch 10/20, Loss: 4.942607879638672, Test_Loss: 5.113235950469971\n",
      "Epoch 11/20, Loss: 4.7743353843688965, Test_Loss: 4.94362735748291\n",
      "Epoch 12/20, Loss: 4.622028827667236, Test_Loss: 4.786988735198975\n",
      "Epoch 13/20, Loss: 4.483788013458252, Test_Loss: 4.643230438232422\n",
      "Epoch 14/20, Loss: 4.35901403427124, Test_Loss: 4.513043403625488\n",
      "Epoch 15/20, Loss: 4.247909069061279, Test_Loss: 4.3974199295043945\n",
      "Epoch 16/20, Loss: 4.151031970977783, Test_Loss: 4.297257900238037\n",
      "Epoch 17/20, Loss: 4.068924427032471, Test_Loss: 4.213108539581299\n",
      "Epoch 18/20, Loss: 4.001837730407715, Test_Loss: 4.145022869110107\n",
      "Epoch 19/20, Loss: 3.9496333599090576, Test_Loss: 4.092474937438965\n",
      "Epoch 20/20, Loss: 3.911655902862549, Test_Loss: 4.054340839385986\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    # for i in range(len(weights)):\n",
    "    #     assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMSGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg model\n",
    "np.random.seed(10)\n",
    "regression_feed = Sequential(Linear(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = MSELoss() \n",
    "optimizer = Adam(regression_feed.parameters(), lr=0.1, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor: 8.24588680267334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = regression_feed(X_reg_test_tensor)\n",
    "loss = criterion(y_preds, y_reg_test_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 7.836653232574463, Test_Loss: 7.7674407958984375\n",
      "Epoch 2/20, Loss: 7.357775688171387, Test_Loss: 7.3439226150512695\n",
      "Epoch 3/20, Loss: 6.935904502868652, Test_Loss: 6.968876838684082\n",
      "Epoch 4/20, Loss: 6.564380168914795, Test_Loss: 6.6364617347717285\n",
      "Epoch 5/20, Loss: 6.2371506690979, Test_Loss: 6.3414692878723145\n",
      "Epoch 6/20, Loss: 5.9488091468811035, Test_Loss: 6.079273223876953\n",
      "Epoch 7/20, Loss: 5.694527626037598, Test_Loss: 5.8458051681518555\n",
      "Epoch 8/20, Loss: 5.470038890838623, Test_Loss: 5.637509346008301\n",
      "Epoch 9/20, Loss: 5.271603584289551, Test_Loss: 5.451310634613037\n",
      "Epoch 10/20, Loss: 5.095963478088379, Test_Loss: 5.284557342529297\n",
      "Epoch 11/20, Loss: 4.94028902053833, Test_Loss: 5.134982585906982\n",
      "Epoch 12/20, Loss: 4.802173137664795, Test_Loss: 5.000657081604004\n",
      "Epoch 13/20, Loss: 4.679513931274414, Test_Loss: 4.879941463470459\n",
      "Epoch 14/20, Loss: 4.570545196533203, Test_Loss: 4.7714409828186035\n",
      "Epoch 15/20, Loss: 4.473757743835449, Test_Loss: 4.673976421356201\n",
      "Epoch 16/20, Loss: 4.387869358062744, Test_Loss: 4.586535930633545\n",
      "Epoch 17/20, Loss: 4.311755180358887, Test_Loss: 4.508236885070801\n",
      "Epoch 18/20, Loss: 4.244472026824951, Test_Loss: 4.438314914703369\n",
      "Epoch 19/20, Loss: 4.185180187225342, Test_Loss: 4.3760881423950195\n",
      "Epoch 20/20, Loss: 4.133159637451172, Test_Loss: 4.320935249328613\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = regression_feed(X_reg_tensor)\n",
    "    loss = criterion(y_pred, y_reg_tensor)\n",
    "    loss.backward()\n",
    "    weights = [param.data for param in regression_feed.parameters()]\n",
    "    grads = [param.grad for param in regression_feed.parameters()]\n",
    "    optimizer.step()\n",
    "    updated_weights = [param.data for param in regression_feed.parameters()]\n",
    "    # for i in range(len(weights)):\n",
    "    #     assert np.equal(weights[i] - 0.2*grads[i], updated_weights[i]).all()\n",
    "    y_preds_test = regression_feed(X_reg_test_tensor)\n",
    "    loss_test = criterion(y_preds_test, y_reg_test_tensor)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss.data}, Test_Loss: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
