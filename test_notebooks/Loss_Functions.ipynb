{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karimgamaleldin/projects/KTorch\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from nn import BCELoss, CrossEntropyLoss, MSELoss, BCEWithLogitsLoss, Linear, ReLU, Sigmoid, Softmax\n",
    "from core import KTorch\n",
    "from autograd import Tensor\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch \n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get inputs\n",
    "np.random.seed(0)\n",
    "\n",
    "y_preds = np.random.randint(100, 1000, (32, ))\n",
    "y_true = np.random.randint(100, 1000, (32, ))\n",
    "y_preds == y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Loss: tensor: 3806477.0\n",
      "Mean Loss: tensor: 118952.40625\n"
     ]
    }
   ],
   "source": [
    "y_preds_tensor = Tensor(y_preds)\n",
    "y_true_tensor = Tensor(y_true)\n",
    "\n",
    "# MSE Loss\n",
    "mse_loss_sum = MSELoss(reduction='sum')\n",
    "mse_loss_mean = MSELoss(reduction='mean')\n",
    "\n",
    "# Calculate loss\n",
    "loss_sum = mse_loss_sum(y_preds_tensor, y_true_tensor)\n",
    "loss_mean = mse_loss_mean(y_preds_tensor, y_true_tensor)\n",
    "\n",
    "print(f\"Sum Loss: {loss_sum}\")\n",
    "print(f\"Mean Loss: {loss_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Sum Loss: 3806477\n",
      "Manual Mean Loss: 118952.40625\n"
     ]
    }
   ],
   "source": [
    "# Calculate mse loss manual\n",
    "diff = y_preds - y_true\n",
    "mse_mean = np.mean(diff**2)\n",
    "mse_sum = np.sum(diff**2)\n",
    "\n",
    "print(f\"Manual Sum Loss: {mse_sum}\")\n",
    "print(f\"Manual Mean Loss: {mse_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Sum Loss: 3806477.0\n",
      "Torch Mean Loss: 118952.40625\n"
     ]
    }
   ],
   "source": [
    "y_preds_torch = torch.tensor(y_preds).float()\n",
    "y_true_torch = torch.tensor(y_true).float()\n",
    "\n",
    "# Calculate loss\n",
    "loss_torch_sum = torch.nn.MSELoss(reduction='sum')(y_preds_torch, y_true_torch)\n",
    "loss_torch_mean = torch.nn.MSELoss(reduction='mean')(y_preds_torch, y_true_torch)\n",
    "\n",
    "print(f\"Torch Sum Loss: {loss_torch_sum}\")\n",
    "print(f\"Torch Mean Loss: {loss_torch_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing backprop\n",
    "\n",
    "# input \n",
    "np.random.seed(0)\n",
    "input = np.random.randn(32, 10).astype(np.float32)\n",
    "target = np.random.rand(32, 1).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "x = Tensor(input)\n",
    "y = Tensor(target)\n",
    "\n",
    "# model\n",
    "linear_1 = Linear(10, 5)\n",
    "relu = ReLU()\n",
    "linear_2 = Linear(5, 1)\n",
    "relu_2 = ReLU()\n",
    "\n",
    "# forward pass\n",
    "h1_nn = linear_1(x)\n",
    "h2_nn = relu(h1_nn)\n",
    "h3_nn = linear_2(h2_nn)\n",
    "out = relu_2(h3_nn)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual forward pass\n",
    "weights_1 = linear_1.weight.data\n",
    "bias_1 = linear_1.bias.data\n",
    "weights_2 = linear_2.weight.data\n",
    "bias_2 = linear_2.bias.data\n",
    "\n",
    "h1 = np.dot(input, weights_1) + bias_1\n",
    "h2 = np.maximum(h1, 0)\n",
    "h3 = np.dot(h2, weights_2) + bias_2\n",
    "out_manual = np.maximum(h3, 0)\n",
    "\n",
    "out_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(out.data, out_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss\n",
    "loss = MSELoss(reduction='mean')\n",
    "loss_val = loss(out, y)\n",
    "\n",
    "# Manual loss\n",
    "diff = out_manual - target\n",
    "loss_manual = np.mean(diff**2)\n",
    "\n",
    "np.equal(loss_val.data, loss_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "loss_val.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Manual backward pass\n",
    "dL = np.ones_like(diff)\n",
    "print((loss_val.grad == dL).all())\n",
    "d_diff = dL * 2 * diff / 32\n",
    "d_out_manual = d_diff\n",
    "print((d_out_manual == out.grad).all())\n",
    "d_h3 = d_out_manual * (h3 > 0)\n",
    "print((d_h3 == h3_nn.grad).all())\n",
    "d_weights_2 = np.dot(h2.T, d_h3)\n",
    "d_bias_2 = np.sum(d_h3, axis=0)\n",
    "print((d_weights_2 == linear_2.weight.grad).all())\n",
    "print((d_bias_2 == linear_2.bias.grad).all())\n",
    "d_h2 = np.dot(d_h3, weights_2.T)\n",
    "print((d_h2 == h2_nn.grad).all())\n",
    "d_h1 = d_h2 * (h1 > 0)\n",
    "print((d_h1 == h1_nn.grad).all())\n",
    "d_weights_1 = np.dot(input.T, d_h1)\n",
    "d_bias_1 = np.sum(d_h1, axis=0)\n",
    "print((d_weights_1 == linear_1.weight.grad).all())\n",
    "print((d_bias_1 == linear_1.bias.grad).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing backprop\n",
    "\n",
    "# input \n",
    "np.random.seed(0)\n",
    "input = np.random.randn(32, 10).astype(np.float32)\n",
    "target = np.random.rand(32, 1).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "x = Tensor(input)\n",
    "y = Tensor(target)\n",
    "\n",
    "# model\n",
    "linear_1 = Linear(10, 5)\n",
    "relu = ReLU()\n",
    "linear_2 = Linear(5, 1)\n",
    "relu_2 = ReLU()\n",
    "\n",
    "# forward pass\n",
    "h1_nn = linear_1(x)\n",
    "h2_nn = relu(h1_nn)\n",
    "h3_nn = linear_2(h2_nn)\n",
    "out = relu_2(h3_nn)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual forward pass\n",
    "weights_1 = linear_1.weight.data\n",
    "bias_1 = linear_1.bias.data\n",
    "weights_2 = linear_2.weight.data\n",
    "bias_2 = linear_2.bias.data\n",
    "\n",
    "h1 = np.dot(input, weights_1) + bias_1\n",
    "h2 = np.maximum(h1, 0)\n",
    "h3 = np.dot(h2, weights_2) + bias_2\n",
    "out_manual = np.maximum(h3, 0)\n",
    "\n",
    "out_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(out.data, out_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss\n",
    "loss = MSELoss(reduction='sum')\n",
    "loss_val = loss(out, y)\n",
    "\n",
    "# Manual loss\n",
    "diff = out_manual - target\n",
    "loss_manual = np.sum(diff**2)\n",
    "\n",
    "np.equal(loss_val.data, loss_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "loss_val.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Manual backward pass\n",
    "dL = np.ones_like(diff)\n",
    "print((loss_val.grad == dL).all())\n",
    "d_diff = dL * 2 * diff\n",
    "d_out_manual = d_diff\n",
    "print((d_out_manual == out.grad).all())\n",
    "d_h3 = d_out_manual * (h3 > 0)\n",
    "print((d_h3 == h3_nn.grad).all())\n",
    "d_weights_2 = np.dot(h2.T, d_h3)\n",
    "d_bias_2 = np.sum(d_h3, axis=0)\n",
    "print((d_weights_2 == linear_2.weight.grad).all())\n",
    "print((d_bias_2 == linear_2.bias.grad).all())\n",
    "d_h2 = np.dot(d_h3, weights_2.T)\n",
    "print((d_h2 == h2_nn.grad).all())\n",
    "d_h1 = d_h2 * (h1 > 0)\n",
    "print((d_h1 == h1_nn.grad).all())\n",
    "d_weights_1 = np.dot(input.T, d_h1)\n",
    "d_bias_1 = np.sum(d_h1, axis=0)\n",
    "print((d_weights_1 == linear_1.weight.grad).all())\n",
    "print((d_bias_1 == linear_1.bias.grad).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: tensor: 1.1908915042877197\n",
      "Sum Loss: tensor: 38.10852813720703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get inputs\n",
    "np.random.seed(0)\n",
    "inputs = np.random.randn(32, 10).astype(np.float32)\n",
    "targets = np.random.randint(0, 2, (32, 1)).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "x = Tensor(inputs)\n",
    "y = Tensor(targets)\n",
    "\n",
    "# Try forward pass of bce loss\n",
    "preds = np.random.rand(32, 1).astype(np.float32)\n",
    "preds_tensor = Tensor(preds)\n",
    "\n",
    "bce_loss_mean = BCELoss(reduction='mean')\n",
    "bce_loss_sum = BCELoss(reduction='sum')\n",
    "\n",
    "loss_mean = bce_loss_mean(preds_tensor, y)\n",
    "loss_sum = bce_loss_sum(preds_tensor, y)\n",
    "\n",
    "print(f\"Mean Loss: {loss_mean}\")\n",
    "print(f\"Sum Loss: {loss_sum}\")\n",
    "\n",
    "loss_mean.data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Mean Loss: 1.1908915042877197\n",
      "Manual Sum Loss: 38.10852813720703\n"
     ]
    }
   ],
   "source": [
    "# Manual loss calculation\n",
    "log_1 = np.log(preds).astype(np.float32)\n",
    "log_2 = np.log(1 - preds).astype(np.float32)\n",
    "log_1 = np.clip(log_1, -100, float('inf'))\n",
    "log_2 = np.clip(log_2, -100, float('inf'))\n",
    "loss_term_1 = - targets * log_1\n",
    "loss_term_2 = - (1 - targets) * log_2\n",
    "loss = loss_term_1 + loss_term_2\n",
    "loss_manual_mean = np.mean(loss)\n",
    "loss_manual_sum = np.sum(loss)\n",
    "\n",
    "print(f\"Manual Mean Loss: {loss_manual_mean}\")\n",
    "print(f\"Manual Sum Loss: {loss_manual_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Mean Loss: 1.1908913850784302\n",
      "Torch Sum Loss: 38.108524322509766\n"
     ]
    }
   ],
   "source": [
    "# Check torch\n",
    "preds_torch = torch.tensor(preds).float()\n",
    "targets_torch = torch.tensor(targets).float()\n",
    "\n",
    "loss_torch_mean = torch.nn.BCELoss(reduction='mean')(preds_torch, targets_torch)\n",
    "loss_torch_sum = torch.nn.BCELoss(reduction='sum')(preds_torch, targets_torch)\n",
    "\n",
    "print(f\"Torch Mean Loss: {loss_torch_mean}\")\n",
    "print(f\"Torch Sum Loss: {loss_torch_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check loss values\n",
    "np.equal(loss_mean.data, loss_manual_mean), np.equal(loss_sum.data, loss_manual_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "np.random.seed(0)\n",
    "\n",
    "layer_1 = Linear(10, 5)\n",
    "relu = ReLU()\n",
    "layer_2 = Linear(5, 1)\n",
    "sigmoid = Sigmoid()\n",
    "\n",
    "# Forward pass\n",
    "h1 = layer_1(x)\n",
    "h2 = relu(h1)\n",
    "h3 = layer_2(h2)\n",
    "out = sigmoid(h3)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual forward pass\n",
    "weights_1 = layer_1.weight.data\n",
    "bias_1 = layer_1.bias.data\n",
    "weights_2 = layer_2.weight.data\n",
    "bias_2 = layer_2.bias.data\n",
    "\n",
    "h1_manual = np.dot(inputs, weights_1) + bias_1\n",
    "h2_manual = np.maximum(h1_manual, 0)\n",
    "h3_manual = np.dot(h2_manual, weights_2) + bias_2\n",
    "out_manual = 1 / (1 + np.exp(-h3_manual))\n",
    "\n",
    "out_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the outputs are the same\n",
    "np.equal(out.data, out_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss\n",
    "bce_loss = BCELoss(reduction='mean')\n",
    "loss_val = bce_loss(out, y)\n",
    "\n",
    "# Manual loss\n",
    "log_1 = np.log(out_manual).astype(np.float32)\n",
    "sub_out_manual = 1 - out_manual\n",
    "log_2 = np.log(sub_out_manual).astype(np.float32)\n",
    "log_1_clip = np.clip(log_1, -100, float('inf'))\n",
    "log_2_clip = np.clip(log_2, -100, float('inf'))\n",
    "loss_term_1 = - targets * log_1_clip\n",
    "loss_term_2 = - (1 - targets) * log_2_clip\n",
    "loss = loss_term_1 + loss_term_2\n",
    "loss_manual = np.mean(loss)\n",
    "\n",
    "np.equal(loss_val.data, loss_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "loss_val.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True  *  * clamp(log(sigmoid(ReLU( @  + ) @  + ))) +  *  +  *  * clamp(log(sigmoid(ReLU( @  + ) @  + ) *  + ))\n",
      "True\n",
      "True\n",
      "True clamp(log(sigmoid(ReLU( @  + ) @  + )))\n",
      "True clamp(log(sigmoid(ReLU( @  + ) @  + ) *  + ))\n",
      "True log(sigmoid(ReLU( @  + ) @  + ))\n",
      "True log(sigmoid(ReLU( @  + ) @  + ) *  + )\n",
      "False sigmoid(ReLU( @  + ) @  + )\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Manual backward pass\n",
    "dL = np.ones_like(loss)\n",
    "print((loss_val.grad == dL).all())\n",
    "\n",
    "d_loss = dL / 32\n",
    "print((d_loss == loss_val._prev[0].grad).all(), loss_val._prev[0].label)\n",
    "\n",
    "d_loss_term_1 = d_loss\n",
    "print((d_loss_term_1 == loss_val._prev[0]._prev[0].grad).all()) \n",
    "\n",
    "d_loss_term_2 = d_loss\n",
    "print((d_loss_term_1 == loss_val._prev[0]._prev[1].grad).all()) \n",
    "\n",
    "d_log_1_clip = - targets * d_loss_term_1\n",
    "print((d_log_1_clip == loss_val._prev[0]._prev[0]._prev[1].grad).all(), loss_val._prev[0]._prev[0]._prev[1].label) \n",
    "\n",
    "d_log_2_clip = d_loss_term_2 * - (1 - targets)\n",
    "print((d_log_2_clip == loss_val._prev[0]._prev[1]._prev[1].grad).all(), loss_val._prev[0]._prev[1]._prev[1].label)\n",
    "\n",
    "d_log_1  = d_log_1_clip * (log_1 > -100)\n",
    "print((d_log_1 == loss_val._prev[0]._prev[0]._prev[1]._prev[0].grad).all(), loss_val._prev[0]._prev[0]._prev[1]._prev[0].label)\n",
    "\n",
    "d_log_2 = d_log_2_clip * (log_2 > -100)\n",
    "print((d_log_2 == loss_val._prev[0]._prev[1]._prev[1]._prev[0].grad).all(), loss_val._prev[0]._prev[1]._prev[1]._prev[0].label)\n",
    "\n",
    "d_out_manual = d_log_1  / out_manual\n",
    "d_sub_out_manual = d_log_2 / sub_out_manual\n",
    "d_out_manual = d_out_manual - d_sub_out_manual\n",
    "print((d_out_manual == out.grad).all(), out.label)\n",
    "\n",
    "d_h3_manual = d_out_manual * out_manual * (1 - out_manual)  \n",
    "print((d_h3_manual == h3.grad).all())\n",
    "\n",
    "d_weights_2 = np.dot(h2_manual.T, d_h3_manual)\n",
    "d_bias_2 = np.sum(d_h3_manual, axis=0)\n",
    "print((d_weights_2 == layer_2.weight.grad).all())\n",
    "\n",
    "d_h2_manual = np.dot(d_h3_manual, weights_2.T)\n",
    "print((d_h2_manual == h2.grad).all())\n",
    "\n",
    "d_h1_manual = d_h2_manual * (h1_manual > 0)\n",
    "print((d_h1_manual == h1.grad).all())\n",
    "\n",
    "d_weights_1 = np.dot(inputs.T, d_h1_manual)\n",
    "d_bias_1 = np.sum(d_h1_manual, axis=0)\n",
    "print((d_weights_1 == layer_1.weight.grad).all())\n",
    "print((d_bias_1 == layer_1.bias.grad).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Loss: 33.56257629394531\n",
      "Torch Logits Loss: 24.625078201293945\n",
      "Torch Sum Loss: 1074.00244140625\n"
     ]
    }
   ],
   "source": [
    "# Get inputs\n",
    "np.random.seed(0)\n",
    "inputs = np.random.randn(32, 10).astype(np.float32)\n",
    "targets = np.random.randint(0, 2, (32, 1)).astype(np.float32)\n",
    "preds = np.random.randint(-100, 100, (32, 1)).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "torch_x = torch.tensor(inputs).float  ()\n",
    "torch_y = torch.tensor(targets).float()\n",
    "torch_preds = torch.tensor(preds).float()\n",
    "torch_sigmoid = torch.nn.Sigmoid()(torch_preds)\n",
    "\n",
    "# Calculate loss\n",
    "torch_loss = torch.nn.BCELoss(reduction='mean')(torch_sigmoid, torch_y)\n",
    "torch_sum_loss = torch.nn.BCELoss(reduction='sum')(torch_sigmoid, torch_y)\n",
    "torch_logits_loss = torch.nn.BCEWithLogitsLoss(reduction='mean')(torch_preds, torch_y)\n",
    "\n",
    "print(f\"Torch Loss: {torch_loss}\")\n",
    "print(f\"Torch Logits Loss: {torch_logits_loss}\")\n",
    "print(f\"Torch Sum Loss: {torch_sum_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: tensor: 11.187578201293945\n",
      "Sum Loss: tensor: 358.00250244140625\n",
      "BCE Loss: tensor: 33.56257629394531\n"
     ]
    }
   ],
   "source": [
    "# Get inputs\n",
    "np.random.seed(0)\n",
    "inputs = np.random.randn(32, 10).astype(np.float32)\n",
    "targets = np.random.randint(0, 2, (32, 1)).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "x = Tensor(inputs)\n",
    "y = Tensor(targets)\n",
    "\n",
    "# Try forward pass of bce loss\n",
    "preds = np.random.randint(-100, 100, (32, 1)).astype(np.float32)\n",
    "preds_tensor = Tensor(preds)\n",
    "sig_output = KTorch.sigmoid(preds_tensor) \n",
    "\n",
    "bce_logit_loss_mean = BCEWithLogitsLoss(reduction='mean')\n",
    "bce_logit_loss_sum = BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "bce = BCELoss(reduction='mean')\n",
    "bce_loss_mean = bce(sig_output, y)\n",
    "\n",
    "loss_mean = bce_logit_loss_mean(preds_tensor, y)\n",
    "loss_sum = bce_logit_loss_sum(preds_tensor, y)\n",
    "\n",
    "print(f\"Mean Loss: {loss_mean}\")\n",
    "print(f\"Sum Loss: {loss_sum}\")\n",
    "print(f\"BCE Loss: {bce_loss_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Mean Loss: 33.56257629394531\n",
      "Manual Sum Loss: 1074.00244140625\n"
     ]
    }
   ],
   "source": [
    "# Manual loss calculation\n",
    "sigmoid_output = 1 / (1 + np.exp(-preds))\n",
    "log_1 = np.log(sigmoid_output).astype(np.float32)\n",
    "log_2 = np.log(1 - sigmoid_output).astype(np.float32)\n",
    "log_1 = np.clip(log_1, -100, float('inf'))\n",
    "log_2 = np.clip(log_2, -100, float('inf'))\n",
    "loss_term_1 = - targets * log_1\n",
    "loss_term_2 = - (1 - targets) * log_2\n",
    "loss = loss_term_1 + loss_term_2\n",
    "loss_manual_mean = np.mean(loss)\n",
    "loss_manual_sum = np.sum(loss)\n",
    "\n",
    "print(f\"Manual Mean Loss: {loss_manual_mean}\")\n",
    "print(f\"Manual Sum Loss: {loss_manual_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Mean Loss: 24.625078201293945\n",
      "Torch Sum Loss: 788.0025024414062\n",
      "Torch BCE Loss: 33.56257629394531\n",
      "Torch BCE Loss 2: 1074.00244140625\n"
     ]
    }
   ],
   "source": [
    "# Check torch\n",
    "preds_torch = torch.tensor(preds).float()\n",
    "targets_torch = torch.tensor(targets).float()\n",
    "sigmoid_output_torch = torch.nn.Sigmoid()(preds_torch)\n",
    "sigmoid_output_torch_2 = torch.tensor(sig_output.data).float()\n",
    "\n",
    "loss_torch_mean = torch.nn.BCEWithLogitsLoss(reduction='mean')(preds_torch, targets_torch)\n",
    "loss_torch_sum = torch.nn.BCEWithLogitsLoss(reduction='sum')(preds_torch, targets_torch)\n",
    "loss_torch_bce = torch.nn.BCELoss(reduction='mean')(sigmoid_output_torch, targets_torch)\n",
    "loss_torch_bce_2 = torch.nn.BCELoss(reduction='sum')(sigmoid_output_torch_2, targets_torch)\n",
    "\n",
    "print(f\"Torch Mean Loss: {loss_torch_mean}\")\n",
    "print(f\"Torch Sum Loss: {loss_torch_sum}\")\n",
    "print(f\"Torch BCE Loss: {loss_torch_bce}\")\n",
    "print(f\"Torch BCE Loss 2: {loss_torch_bce_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sigmoid_output_torch.numpy() == sigmoid_output.data).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check loss values\n",
    "np.equal(loss_mean.data, loss_manual_mean), np.equal(loss_sum.data, loss_manual_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "np.random.seed(0)\n",
    "\n",
    "layer_1 = Linear(10, 5)\n",
    "relu = ReLU()\n",
    "layer_2 = Linear(5, 1)\n",
    "\n",
    "# Forward pass\n",
    "h1 = layer_1(x)\n",
    "h2 = relu(h1)\n",
    "out = layer_2(h2)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual forward pass\n",
    "weights_1 = layer_1.weight.data\n",
    "bias_1 = layer_1.bias.data\n",
    "weights_2 = layer_2.weight.data\n",
    "bias_2 = layer_2.bias.data\n",
    "\n",
    "h1_manual = np.dot(inputs, weights_1) + bias_1\n",
    "h2_manual = np.maximum(h1_manual, 0)\n",
    "h3_manual = np.dot(h2_manual, weights_2) + bias_2\n",
    "out_manual = 1 / (1 + np.exp(-h3_manual))\n",
    "\n",
    "out_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the outputs are the same\n",
    "np.equal(Sigmoid()(out).data, out_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss\n",
    "bce_loss = BCEWithLogitsLoss(reduction='mean')\n",
    "loss_val = bce_loss(out, y)\n",
    "\n",
    "# Manual loss\n",
    "log_1 = np.log(out_manual).astype(np.float32)\n",
    "sub_out_manual = 1 - out_manual\n",
    "log_2 = np.log(sub_out_manual).astype(np.float32)\n",
    "log_1_clip = np.clip(log_1, -100, float('inf'))\n",
    "log_2_clip = np.clip(log_2, -100, float('inf'))\n",
    "loss_term_1 = - targets * log_1_clip\n",
    "loss_term_2 = - (1 - targets) * log_2_clip\n",
    "loss = loss_term_1 + loss_term_2\n",
    "loss_manual = np.mean(loss)\n",
    "\n",
    "np.equal(loss_val.data, loss_manual).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "loss_val.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True  *  +  * ReLU( @  + ) @  +  + log(exp(abs(ReLU( @  + ) @  + ) * ) + )\n",
      "True\n",
      "True\n",
      "False ReLU( @  + ) @  + \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m((d_log_1_clip \u001b[38;5;241m==\u001b[39m loss_val\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mall(), loss_val\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlabel) \n\u001b[1;32m     17\u001b[0m d_log_2_clip \u001b[38;5;241m=\u001b[39m d_loss_term_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m targets)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m((d_log_2_clip \u001b[38;5;241m==\u001b[39m \u001b[43mloss_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prev\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prev\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prev\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mall(), loss_val\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlabel)\n\u001b[1;32m     20\u001b[0m d_log_1  \u001b[38;5;241m=\u001b[39m d_log_1_clip \u001b[38;5;241m*\u001b[39m (log_1 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m((d_log_1 \u001b[38;5;241m==\u001b[39m loss_val\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mall(), loss_val\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_prev[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlabel)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Manual backward pass\n",
    "dL = np.ones_like(loss)\n",
    "print((loss_val.grad == dL).all())\n",
    "\n",
    "d_loss = dL / 32\n",
    "print((d_loss == loss_val._prev[0].grad).all(), loss_val._prev[0].label)\n",
    "\n",
    "d_loss_term_1 = d_loss\n",
    "print((d_loss_term_1 == loss_val._prev[0]._prev[0].grad).all()) \n",
    "\n",
    "d_loss_term_2 = d_loss\n",
    "print((d_loss_term_1 == loss_val._prev[0]._prev[1].grad).all()) \n",
    "\n",
    "d_log_1_clip = - targets * d_loss_term_1\n",
    "print((d_log_1_clip == loss_val._prev[0]._prev[0]._prev[1].grad).all(), loss_val._prev[0]._prev[0]._prev[1].label) \n",
    "\n",
    "d_log_2_clip = d_loss_term_2 * - (1 - targets)\n",
    "print((d_log_2_clip == loss_val._prev[0]._prev[1]._prev[1].grad).all(), loss_val._prev[0]._prev[1]._prev[1].label)\n",
    "\n",
    "d_log_1  = d_log_1_clip * (log_1 > -100)\n",
    "print((d_log_1 == loss_val._prev[0]._prev[0]._prev[1]._prev[0].grad).all(), loss_val._prev[0]._prev[0]._prev[1]._prev[0].label)\n",
    "\n",
    "d_log_2 = d_log_2_clip * (log_2 > -100)\n",
    "print((d_log_2 == loss_val._prev[0]._prev[1]._prev[1]._prev[0].grad).all(), loss_val._prev[0]._prev[1]._prev[1]._prev[0].label)\n",
    "\n",
    "d_out_manual = d_log_1  / out_manual\n",
    "d_sub_out_manual = d_log_2 / sub_out_manual\n",
    "d_out_manual = d_out_manual - d_sub_out_manual\n",
    "\n",
    "d_h3_manual = d_out_manual * out_manual * (1 - out_manual)  \n",
    "print((d_h3_manual == out.grad).all())\n",
    "\n",
    "d_weights_2 = np.dot(h2_manual.T, d_h3_manual)\n",
    "d_bias_2 = np.sum(d_h3_manual, axis=0)\n",
    "print((d_weights_2 == layer_2.weight.grad).all())\n",
    "\n",
    "d_h2_manual = np.dot(d_h3_manual, weights_2.T)\n",
    "print((d_h2_manual == h2.grad).all())\n",
    "\n",
    "d_h1_manual = d_h2_manual * (h1_manual > 0)\n",
    "print((d_h1_manual == h1.grad).all())\n",
    "\n",
    "d_weights_1 = np.dot(inputs.T, d_h1_manual)\n",
    "d_bias_1 = np.sum(d_h1_manual, axis=0)\n",
    "print((d_weights_1 == layer_1.weight.grad).all())\n",
    "print((d_bias_1 == layer_1.bias.grad).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: tensor: 0.28979283571243286\n",
      "Sum Loss: tensor: 92.73370361328125\n"
     ]
    }
   ],
   "source": [
    "# Get inputs\n",
    "np.random.seed(0)\n",
    "inputs = np.random.randn(32, 10).astype(np.float32)\n",
    "targets = np.random.randint(0, 10, (32, 1)).astype(np.float32)\n",
    "y_preds = np.random.randn(32, 10).astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "x = Tensor(inputs)\n",
    "y = Tensor(targets)\n",
    "y_preds_tensor = Tensor(y_preds)\n",
    "\n",
    "# Try forward pass of cross entropy loss\n",
    "cross_entropy_loss_mean = CrossEntropyLoss(reduction='mean')\n",
    "cross_entropy_loss_sum = CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "loss_mean = cross_entropy_loss_mean(y_preds_tensor, y)\n",
    "loss_sum = cross_entropy_loss_sum(y_preds_tensor, y)\n",
    "\n",
    "print(f\"Mean Loss: {loss_mean}\")\n",
    "print(f\"Sum Loss: {loss_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Mean Loss: 0.28979283571243286\n",
      "Manual Sum Loss: 92.73370361328125\n"
     ]
    }
   ],
   "source": [
    "# Manual loss calculation\n",
    "one_hot_targets = np.zeros_like(y_preds)\n",
    "targets = targets.astype(np.int32)\n",
    "one_hot_targets[np.arange(len(targets)), targets.flatten()] = 1\n",
    "\n",
    "y_preds = np.exp(y_preds - np.max(y_preds, axis=1, keepdims=True))\n",
    "y_preds = y_preds / np.sum(y_preds, axis=1, keepdims=True)\n",
    "log_y_preds = np.log(y_preds)\n",
    "loss = - one_hot_targets * log_y_preds\n",
    "loss_manual_mean = np.mean(loss)\n",
    "loss_manual_sum = np.sum(loss)\n",
    "\n",
    "print(f\"Manual Mean Loss: {loss_manual_mean}\")\n",
    "print(f\"Manual Sum Loss: {loss_manual_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(loss_mean.data, loss_manual_mean), np.equal(loss_sum.data, loss_manual_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10]) torch.Size([32, 1])\n",
      "Pytorch Mean Loss: 74.43683624267578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "x_torch = torch.tensor(inputs)\n",
    "y_torch = torch.tensor(targets).long()\n",
    "y_preds_torch = torch.tensor(y_preds)\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "print(y_preds_torch.shape, y_torch.shape)\n",
    "loss_torch = cross_entropy_loss(y_preds_torch, y_torch.flatten())\n",
    "\n",
    "print(f\"Pytorch Mean Loss: {loss_torch.numpy()}\")\n",
    "np.equal(loss_mean.data, loss_torch.numpy()), np.equal(loss_sum.data, loss_torch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
